{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T00:46:05.438514Z",
     "start_time": "2023-02-28T00:46:04.731523Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bibliotecas\n",
    "\n",
    "# Automa√ß√£o Web\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Web Scraping e manipula√ß√¢o dos dados\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Auxiliares\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "\n",
    "class google_maps_scraper():\n",
    "\n",
    "    # Fun√ß√£o construtora\n",
    "    def __init__(self, locais : list[str]):\n",
    "\n",
    "        print('Iniciando Scraper...')\n",
    "        self.__locais = locais\n",
    "\n",
    "\n",
    "    # Fun√ß√£o que clica no bot√£o de ir para as avalia√ß√µes\n",
    "    def __clica_avaliacoes(self):\n",
    "        # Constantes\n",
    "        ELEM_AVAL = '//span[contains (text(), \"avalia√ß√µes\")]'\n",
    "        ELEM_AVAL_2 = '//*[contains (text(), \"Avalia√ß√µes\")]'\n",
    "        \n",
    "        try:\n",
    "            avaliacoes = WebDriverWait(self.__driver, 10).until(EC.presence_of_element_located((By.XPATH, ELEM_AVAL)))\n",
    "            avaliacoes = WebDriverWait(self.__driver, 10).until(EC.element_to_be_clickable((By.XPATH, ELEM_AVAL)))\n",
    "            avaliacoes.click()\n",
    "            sleep(0.5)\n",
    "        except:\n",
    "            avaliacoes = WebDriverWait(self.__driver, 10).until(EC.presence_of_element_located((By.XPATH, ELEM_AVAL_2)))\n",
    "            avaliacoes = WebDriverWait(self.__driver, 10).until(EC.element_to_be_clickable((By.XPATH, ELEM_AVAL_2)))\n",
    "            avaliacoes.click()\n",
    "            sleep(0.5)\n",
    "\n",
    "    # Fun√ß√£o para filtrar os coment√°rios mais recentes\n",
    "    def __filtra_recente(self):\n",
    "        # Contantes\n",
    "        ELEM_FILTRO = '//*[contains (text(), \"Ordenar\")]'\n",
    "        ELEM_RECENTE = '//*[@id=\"action-menu\"]/div[2]'\n",
    "        ELEM_FILTRO_2 = '//*[contains (text(), \"Mais relevantes\")]'\n",
    "        \n",
    "        # Tenta clicar no bot√£o de filtro padr√£o\n",
    "        try:\n",
    "            # Clicando no bot√£o de filtro\n",
    "            filtro = WebDriverWait(self.__driver, 10).until(EC.presence_of_element_located((By.XPATH, ELEM_FILTRO)))\n",
    "            filtro.click()\n",
    "            sleep(0.25)\n",
    "\n",
    "            # Clicando no bot√£o de mais recente\n",
    "            recente = WebDriverWait(self.__driver, 10).until(EC.presence_of_element_located((By.XPATH, ELEM_RECENTE)))\n",
    "            recente = WebDriverWait(self.__driver, 10).until(EC.element_to_be_clickable((By.XPATH, ELEM_RECENTE)))\n",
    "            recente.click()\n",
    "            sleep(0.25)\n",
    "            \n",
    "        # Se n√£o encontra, tenta clicar no outro tipo de bot√£o\n",
    "        except:\n",
    "            try:\n",
    "                # Clicando no bot√£o de filtro\n",
    "                filtro = WebDriverWait(self.__driver, 10).until(EC.presence_of_element_located((By.XPATH, ELEM_FILTRO_2)))\n",
    "                filtro.click()\n",
    "                sleep(0.25)\n",
    "\n",
    "                # Clicando no bot√£o de mais recente\n",
    "                recente = WebDriverWait(self.__driver, 10).until(EC.presence_of_element_located((By.XPATH, ELEM_RECENTE)))\n",
    "                recente = WebDriverWait(self.__driver, 10).until(EC.element_to_be_clickable((By.XPATH, ELEM_RECENTE)))\n",
    "                recente.click()\n",
    "                sleep(0.25)\n",
    "            except:\n",
    "                print('N√£o foi poss√≠vel fazer o filtro!')\n",
    "\n",
    "    # Fun√ß√£o que faz o scroll na p√°gina\n",
    "    def __scroll(self):\n",
    "        # Constantes\n",
    "        ELEM_SCROLL = '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]'\n",
    "        \n",
    "        try:\n",
    "            scroll = WebDriverWait(self.__driver, 10).until(EC.presence_of_element_located((By.XPATH, ELEM_SCROLL)))\n",
    "            self.__driver.execute_script(\n",
    "                    'arguments[0].scrollTop = arguments[0].scrollHeight', \n",
    "                        scroll\n",
    "                    )\n",
    "            sleep(0.25)\n",
    "        except:\n",
    "            print('N√£o foi poss√≠vel fazer o scroll!')\n",
    "\n",
    "    # Fun√ß√£o que inicia o processo\n",
    "    def coletar(self, quantidade_de_comentarios : int):\n",
    "\n",
    "        self.__quantidade_de_comentarios = quantidade_de_comentarios\n",
    "        \n",
    "        print(f'Hor√°rio de in√≠cio: {datetime.now()}')\n",
    "\n",
    "        URL_BASE = 'https://www.google.com.br/maps/search/'\n",
    "\n",
    "        # Lista com os dados coletadost\n",
    "        dd_notas = []\n",
    "        dd_palavras = []\n",
    "        df_comentarios = pd.DataFrame()\n",
    "        \n",
    "        # Iniciando webdriver\n",
    "        self.__driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "        # Percorrendo os locais\n",
    "        for i in range(len(self.__locais)):\n",
    "\n",
    "            # Coletando informa√ß√£o do momento da coleta\n",
    "            now = datetime.now()\n",
    "            stamp_coleta = now.strftime(\"%d/%m/%y %H:%M:%S\")\n",
    "            \n",
    "            local = self.__locais[i]\n",
    "            print('=' * 25)\n",
    "            print(local)\n",
    "\n",
    "            # Entrando na URL de cada local\n",
    "            self.__driver.get(URL_BASE + local)\n",
    "            sleep(0.25)\n",
    "\n",
    "            try:\n",
    "\n",
    "                try: \n",
    "                    # Clicando no bot√£o para ir at√© as avalia√ß√µes\n",
    "                    self.__clica_avaliacoes()\n",
    "\n",
    "                except:\n",
    "                    try:\n",
    "                        soup = BeautifulSoup(self.__driver.page_source, \"html5lib\")\n",
    "                        link = soup.find('a', {'aria-label' : re.compile(local)}).get('href')\n",
    "                        self.__driver.get(link)\n",
    "                        self.__clica_avaliacoes()\n",
    "\n",
    "                    except:               \n",
    "                        print(f'N√£o foi poss√≠vel encontrar o local de nome {local}')\n",
    "                        continue\n",
    "\n",
    "                # Coletando qtd coment√°rios e avalia√ß√£o geral do lugar\n",
    "                sleep(2)\n",
    "                soup = BeautifulSoup(self.__driver.page_source, \"html5lib\")\n",
    "                html_comentarios = soup.find('div', text = re.compile('[0-9]+\\.?[0-9]* coment√°rios'))\n",
    "                qtd_comentarios = str(html_comentarios.contents[0])\n",
    "\n",
    "                # Tratando comentarios para coletar apenas o valor numerico na forma de \"int\"\n",
    "                string_qtd = re.findall('[0-9]+\\.?[0-9]*', qtd_comentarios)[0]\n",
    "                if '.' in string_qtd:\n",
    "                    string_qtd = string_qtd.replace('.', '')\n",
    "\n",
    "                qtd_comentarios_num = int(string_qtd)\n",
    "\n",
    "                html_nota = html_comentarios.find_previous_siblings()[-1]\n",
    "                nota = html_nota.contents[0]\n",
    "\n",
    "                dd_notas.append((\n",
    "                    local,\n",
    "                    nota,\n",
    "                    qtd_comentarios_num,\n",
    "                    stamp_coleta,\n",
    "                ))\n",
    "\n",
    "                # Coletando palavras-chave\n",
    "                for html in soup.find_all(attrs = {'data-tooltip' : re.compile('\\w+, mencionado em [0-9]+ avalia√ß√µes')}):\n",
    "\n",
    "                    palavra_chave = html.get('data-tooltip').split(',')[0]\n",
    "                    mencoes_raw = html.get('data-tooltip').split(',')[1]\n",
    "                    mencoes = mencoes_raw.replace('mencionado em', '').replace('avalia√ß√µes', '').strip()\n",
    "\n",
    "                    dd_palavras.append((local,\n",
    "                                        palavra_chave,\n",
    "                                        mencoes,\n",
    "                                        stamp_coleta))\n",
    "\n",
    "                # Verificando se √© necess√°rio coletar coment√°rios\n",
    "                if self.__quantidade_de_comentarios > 1:\n",
    "\n",
    "                # Filtrando coment√°rios pelos mais recentes\n",
    "                    self.__filtra_recente()\n",
    "                    sleep(1)\n",
    "\n",
    "                    # Definindo a quantidade de coment√°rios\n",
    "                    min_comentarios = self.__quantidade_de_comentarios\n",
    "                    \n",
    "                    # Verificando se a quantidade de comentarios existentes √© suficiente\n",
    "                    if qtd_comentarios_num < min_comentarios:\n",
    "                        min_comentarios = qtd_comentarios_num\n",
    "\n",
    "                    contador = 0\n",
    "                    qtd_texto = 0\n",
    "                    lista_qtd = []\n",
    "                    # Usando scroll na p√°gina\n",
    "                    while qtd_texto < min_comentarios:\n",
    "\n",
    "                        self.__scroll()\n",
    "\n",
    "                        # Capturando coment√°rios\n",
    "                        html = self.__driver.page_source\n",
    "                        soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "                        comentarios = soup.find_all('span', {'class' : 'wiI7pd'})\n",
    "                        listas_comentarios = [comentario.contents for comentario in comentarios]\n",
    "\n",
    "                        # Verificando quantidade de comentarios\n",
    "                        qtd_texto = sum([len(lista) for lista in listas_comentarios])\n",
    "\n",
    "                        if qtd_texto in lista_qtd:\n",
    "                            contador += 1\n",
    "                            if contador == 10:\n",
    "                                print('O m√°ximo de avalia√ß√µes escritas foi coletado!')\n",
    "                                break\n",
    "                        else:\n",
    "                            contador = 0\n",
    "\n",
    "                        lista_qtd.append(qtd_texto)\n",
    "\n",
    "                        print(f'qtd comentarios na p√°gina (min = {min_comentarios}): {qtd_texto}')\n",
    "\n",
    "                    # Colocando os comentarios em um dataframe organizado\n",
    "                    dd_comentarios = [comentario.contents[0] for comentario in comentarios if len(comentario) > 0]\n",
    "\n",
    "                    df2 = pd.DataFrame({\n",
    "                        'nome_do_estabelecimento' : local,\n",
    "                        'comentario' : dd_comentarios,\n",
    "                        'timestamp_coleta' : stamp_coleta,\n",
    "                    })\n",
    "\n",
    "                    df_comentarios = pd.concat([df_comentarios, df2])\n",
    "\n",
    "                elif self.__quantidade_de_comentarios == 0:\n",
    "                    df_comentarios = pd.DataFrame()\n",
    "\n",
    "            except AttributeError as e:\n",
    "                print(f'Ocorreu um erro em {local}')\n",
    "                print(e)\n",
    "                \n",
    "\n",
    "\n",
    "        # Fechando navegador\n",
    "        print(f'Coleta finalizada! Fechando navegador... (Hor√°rio: {datetime.now()})\\n')\n",
    "        self.__driver.quit()\n",
    "\n",
    "        # Montando dataframe com as notas e qtd coment√°rios\n",
    "        df_notas = pd.DataFrame(dd_notas, columns = ['nome_do_estabelecimento',\n",
    "                                                    'nota', \n",
    "                                                    'qtd_comentarios',\n",
    "                                                    'timestamp_coleta',])\n",
    "        \n",
    "        # Montando dataframe com as palavras-chave\n",
    "        df_palavras = pd.DataFrame(dd_palavras, columns = ['nome_do_estabelecimento',\n",
    "                                                        'palavra_chave', \n",
    "                                                        'mencoes',\n",
    "                                                        'timestamp_coleta'])\n",
    "        \n",
    "        # Salvando dados como um dicion√°rio\n",
    "        dados = {\n",
    "            'notas' : df_notas,\n",
    "            'palavras' : df_palavras,\n",
    "            'comentarios' : df_comentarios\n",
    "        }\n",
    "\n",
    "        print(f'\\nHor√°rio de fim: {datetime.now()}')\n",
    "        return dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T00:03:35.205681Z",
     "start_time": "2023-02-28T00:03:34.699744Z"
    }
   },
   "outputs": [],
   "source": [
    "# Baixe o arquivo .py e fa√ßa o import do objeto principal\n",
    "from google_maps_scraper import google_maps_scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T00:34:30.155685Z",
     "start_time": "2023-02-28T00:34:30.144658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Scraper...\n"
     ]
    }
   ],
   "source": [
    "wizard = google_maps_scraper(['Beach Park', 'Petverso Caf√©'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T00:35:14.185530Z",
     "start_time": "2023-02-28T00:34:30.910687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hor√°rio de in√≠cio: 2023-02-27 21:34:30.912689\n",
      "=========================\n",
      "Beach Park\n",
      "qtd comentarios na p√°gina (min = 5): 5\n",
      "=========================\n",
      "Petverso Caf√©\n",
      "qtd comentarios na p√°gina (min = 5): 7\n",
      "Coleta finalizada! Fechando navegador... (Hor√°rio: 2023-02-27 21:35:12.031818)\n",
      "\n",
      "\n",
      "Hor√°rio de fim: 2023-02-27 21:35:14.171001\n"
     ]
    }
   ],
   "source": [
    "dados = wizard.coletar(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T00:36:08.895164Z",
     "start_time": "2023-02-28T00:36:08.879631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nome_do_estabelecimento nota  qtd_comentarios   timestamp_coleta\n",
      "0              Beach Park  4,5              759  27/02/23 21:34:32\n",
      "1           Petverso Caf√©  4,4               39  27/02/23 21:35:04\n"
     ]
    }
   ],
   "source": [
    "print(dados['notas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T00:36:10.292123Z",
     "start_time": "2023-02-28T00:36:10.281607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   nome_do_estabelecimento    palavra_chave mencoes   timestamp_coleta\n",
      "0               Beach Park            pre√ßo      38  27/02/23 21:34:32\n",
      "1               Beach Park         divers√£o      13  27/02/23 21:34:32\n",
      "2               Beach Park  parque aqu√°tico       9  27/02/23 21:34:32\n",
      "3               Beach Park              mar       9  27/02/23 21:34:32\n",
      "4               Beach Park          salgado       7  27/02/23 21:34:32\n",
      "5               Beach Park       brinquedos       6  27/02/23 21:34:32\n",
      "6               Beach Park         crian√ßas       6  27/02/23 21:34:32\n",
      "7               Beach Park          valores       5  27/02/23 21:34:32\n",
      "8               Beach Park          servi√ßo       5  27/02/23 21:34:32\n",
      "9               Beach Park           f√©rias       3  27/02/23 21:34:32\n",
      "10           Petverso Caf√©         ambiente      11  27/02/23 21:35:04\n",
      "11           Petverso Caf√©         gatinhos       8  27/02/23 21:35:04\n",
      "12           Petverso Caf√©            pre√ßo       4  27/02/23 21:35:04\n",
      "13           Petverso Caf√©        decora√ß√£o       3  27/02/23 21:35:04\n",
      "14           Petverso Caf√©           espa√ßo       3  27/02/23 21:35:04\n",
      "15           Petverso Caf√©             bolo       3  27/02/23 21:35:04\n"
     ]
    }
   ],
   "source": [
    "print(dados['palavras'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T00:37:47.351583Z",
     "start_time": "2023-02-28T00:37:47.335546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nome_do_estabelecimento                                         comentario  \\\n",
      "0              Beach Park  Espa√ßo incr√≠vel. Conforto nota 10.\\nSuper priv...   \n",
      "1              Beach Park          (Tradu√ß√£o do Google) OK\\n\\n(Original)\\nOk   \n",
      "2              Beach Park  Maravilhoso! Ambiente a beira da praia, lounge...   \n",
      "3              Beach Park  Pre√ßo salgado e a seleta de frutos do mar R$40...   \n",
      "4              Beach Park  Excelente op√ß√£o, atendimento muito bom e tudo ...   \n",
      "0           Petverso Caf√©  Ambiente massa,comidas maravilhosas e lindos a...   \n",
      "1           Petverso Caf√©                                Proposta inovadora.   \n",
      "2           Petverso Caf√©  Levei minha filha que ficou encantada com os g...   \n",
      "3           Petverso Caf√©              Excelente üëèüëèüëè. Voltarei e recomendo ‚Ä¶   \n",
      "4           Petverso Caf√©  Fui nesse local para conhecer os gatinhos e ac...   \n",
      "5           Petverso Caf√©  √ìtima comida, e depois de comer voc√™ ainda pod...   \n",
      "6           Petverso Caf√©  Fomos conhecer a cafeteira que tem um espa√ßo r...   \n",
      "\n",
      "    timestamp_coleta  \n",
      "0  27/02/23 21:34:32  \n",
      "1  27/02/23 21:34:32  \n",
      "2  27/02/23 21:34:32  \n",
      "3  27/02/23 21:34:32  \n",
      "4  27/02/23 21:34:32  \n",
      "0  27/02/23 21:35:04  \n",
      "1  27/02/23 21:35:04  \n",
      "2  27/02/23 21:35:04  \n",
      "3  27/02/23 21:35:04  \n",
      "4  27/02/23 21:35:04  \n",
      "5  27/02/23 21:35:04  \n",
      "6  27/02/23 21:35:04  \n"
     ]
    }
   ],
   "source": [
    "print(dados['comentarios'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "62c54b5558eead5e1c591ac60cbc5918fb5b35f22e0cf9ea56ce540cc4219c32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
